# Correction Section
run_correction: True
correction_model: IdenticalCorrectionModel
correction_model_args: 
  model_name: Identical

# Dataset Section
eval_datasets:
  # - RAGTruth
  # - FAVA
  # - FaithBench
  - FACTSGrounding

# Response Preprocessing section
run_preprocess: True
preprocessors:
  # - Sentencizer:
  #     decontext: False
  #     input_column: corrected
  #     output_column: processed
  - ClaimExtractor:
      model_path: meta-llama/llama-3.3-70b-instruct
      output_column: extracted
      RPS: 20
      num_proc: 20


# Evaluation Section
# Add metrics as:
# - METRIC_CLASS1:
# - METRIC_CLASS2:
#     METRIC2_KWARGS (Optional)
run_eval: True
eval_metrics:
  - Rouge:
      model_name: Rouge#L
      context_column: claim
  - HHEM:
      model_name: HHEM#2.1-claim
      model_path: vectara/HHEM-2.1
      claim_column: extracted
  - Minicheck:
      model_name: Minicheck#7B-claim
      claim_column: extracted
  - FACTSGJudge:
      model_name: FACTSGJudge#Llama-3.3-70b-json
      RPS: 20
      num_proc: 20
